{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea264e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "class Prm:\n",
    "    def __init__(self, D, H1, H2):\n",
    "        self.D = D\n",
    "        self.H1 = H1\n",
    "        self.H2 = H2\n",
    "        \n",
    "class SMR:\n",
    "    def __init__(self, az, el, x, y, z):\n",
    "        self.az = az\n",
    "        self.el = el\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        \n",
    "class Data:\n",
    "    def __init__(self, smr: SMR, raw_centroid_xy, rvec=None, tvec=None):\n",
    "        self.smr = smr\n",
    "        self.centroids = []\n",
    "        for i in range(len(raw_centroid_xy) // 2):\n",
    "            self.centroids.append([raw_centroid_xy[2 * i], raw_centroid_xy[2 * i + 1]])\n",
    "        # Optional extrinsics parsed directly from dump (solvePnP results)\n",
    "        self.rvec = None if rvec is None else np.asarray(rvec, dtype=np.float64).reshape(3,)\n",
    "        self.tvec = None if tvec is None else np.asarray(tvec, dtype=np.float64).reshape(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81e4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ref_smr_from_txt(file_path):\n",
    "    smrs = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines()[:3]]\n",
    "    data = [list(map(float, line.split(','))) for line in lines]\n",
    "    for row in data:\n",
    "        smrs.append(SMR(None, None, row[0], row[1], row[2]))\n",
    "    return smrs\n",
    "\n",
    "def build_fsinft_from_three_points(p1: np.ndarray, p2: np.ndarray, p3: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build FS frame (FS in FT) from three reference points:\n",
    "      fs_z = p1 - p2; fs_y = cross(-fs_z, p3 - p2); fs_x = cross(fs_y, fs_z)\n",
    "    Returns 3x3 fsinft with columns [fs_x, fs_y, fs_z]. All computations in float64.\n",
    "    \"\"\"\n",
    "    p1 = np.asarray(p1, dtype=np.float64).reshape(3,)\n",
    "    p2 = np.asarray(p2, dtype=np.float64).reshape(3,)\n",
    "    p3 = np.asarray(p3, dtype=np.float64).reshape(3,)\n",
    "    \n",
    "    eps = 1e-12\n",
    "\n",
    "    z_vec = p2 - p1\n",
    "    nz = float(np.linalg.norm(z_vec))\n",
    "    if nz <= eps:\n",
    "        raise ValueError(\"Degenerate FS construction: |p1 - p2| too small\")\n",
    "    z_hat = z_vec / nz\n",
    "\n",
    "    y_vec = np.cross(-z_hat, (p2 - p3))\n",
    "    ny = float(np.linalg.norm(y_vec))\n",
    "    if ny <= eps:\n",
    "        raise ValueError(\"Degenerate FS construction: y axis norm too small (points nearly colinear)\")\n",
    "    y_hat = y_vec / ny\n",
    "\n",
    "    x_vec = np.cross(y_hat, z_hat)\n",
    "    nx = float(np.linalg.norm(x_vec))\n",
    "    if nx <= eps:\n",
    "        raise ValueError(\"Degenerate FS construction: x axis norm too small\")\n",
    "    x_hat = x_vec / nx\n",
    "\n",
    "    # Re-orthogonalize y to ensure perfect orthonormal right-handed frame\n",
    "    y_hat = np.cross(z_hat, x_hat)\n",
    "    y_norm = float(np.linalg.norm(y_hat))\n",
    "    if y_norm > eps:\n",
    "        y_hat = y_hat / y_norm\n",
    "\n",
    "    fsinft = np.column_stack((x_hat, y_hat, z_hat)).astype(np.float64)\n",
    "    \n",
    "    return fsinft\n",
    "\n",
    "def read_iprobe_data_from_dat(file_path):\n",
    "    data_list = []\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        header_line = f.readline().rstrip('\\n\\r')\n",
    "        if not header_line:\n",
    "            raise ValueError(\"Empty file or missing header\")\n",
    "        header_tokens = header_line.split('\\t') if '\\t' in header_line else re.split(r'\\s+', header_line.strip())\n",
    "        token_to_idx = {tok: i for i, tok in enumerate(header_tokens)}\n",
    "        # Build a normalized lookup: remove spaces/underscores/dots and lowercase, e.g., \"RVec X\" -> \"rvecx\"\n",
    "        def _norm(tok: str) -> str:\n",
    "            return re.sub(r'[^0-9a-zA-Z]+', '', tok).lower()\n",
    "        norm_to_tok = {_norm(tok): tok for tok in header_tokens}\n",
    "\n",
    "        def need(tok: str) -> int:\n",
    "            if tok not in token_to_idx:\n",
    "                raise KeyError(f\"Header missing required column '{tok}'\")\n",
    "            return token_to_idx[tok]\n",
    "\n",
    "        def need_any(toks):\n",
    "            for t in toks:\n",
    "                if t in token_to_idx:\n",
    "                    return token_to_idx[t]\n",
    "            raise KeyError(f\"Header missing required columns (any of): {toks}\")\n",
    "\n",
    "        # Required columns\n",
    "        az_idx = need(\"AZ\")\n",
    "        el_idx = need(\"EL\")\n",
    "        bx_idx = need_any([\"Before Comp. X\", \"Before Comp X\", \"Before Comp.X\", \"BeforeComp X\"])\n",
    "        by_idx = need_any([\"Before Comp. Y\", \"Before Comp Y\", \"Before Comp.Y\", \"BeforeComp Y\"])\n",
    "        bz_idx = need_any([\"Before Comp Z.\", \"Before Comp. Z\", \"Before Comp Z\", \"BeforeComp Z\"])\n",
    "\n",
    "        # Optional: rvec/tvec columns from MatchedDataDump if available\n",
    "        def _find_optional_vec(prefix: str):\n",
    "            # Try normalized keys like rvecx, rvecy, rvecz or tvecx, tvecy, tvecz\n",
    "            idxs = []\n",
    "            for axis in ('x', 'y', 'z'):\n",
    "                key_norm = f\"{prefix}{axis}\"\n",
    "                if key_norm in norm_to_tok:\n",
    "                    tok = norm_to_tok[key_norm]\n",
    "                    idxs.append(token_to_idx[tok])\n",
    "                else:\n",
    "                    idxs.append(None)\n",
    "            # If any missing, treat as unavailable\n",
    "            if any(i is None for i in idxs):\n",
    "                return None\n",
    "            return tuple(idxs)\n",
    "\n",
    "        rvec_idx_triplet = _find_optional_vec(\"rvec\")\n",
    "        tvec_idx_triplet = _find_optional_vec(\"tvec\")\n",
    "\n",
    "        # Collect centroid indices\n",
    "        cx_idx = []\n",
    "        cy_idx = []\n",
    "        for i in range(1, 18):\n",
    "            cx_tok = f\"CX{i}\"\n",
    "            cy_tok = f\"CY{i}\"\n",
    "            if cx_tok in token_to_idx and cy_tok in token_to_idx:\n",
    "                cx_idx.append(token_to_idx[cx_tok])\n",
    "                cy_idx.append(token_to_idx[cy_tok])\n",
    "        if len(cx_idx) != 17 or len(cy_idx) != 17:\n",
    "            raise KeyError(\"Header missing some centroid columns CX1..CX17/CY1..CY17\")\n",
    "\n",
    "        # Parse rows\n",
    "        for line in f:\n",
    "            s = line.rstrip('\\n\\r')\n",
    "            if not s:\n",
    "                continue\n",
    "            toks = s.split('\\t') if '\\t' in s else re.split(r'\\s+', s.strip())\n",
    "            max_needed = max([az_idx, el_idx, bx_idx, by_idx, bz_idx] + cx_idx + cy_idx)\n",
    "            if len(toks) <= max_needed:\n",
    "                continue\n",
    "            try:\n",
    "                az = float(toks[az_idx])\n",
    "                el = float(toks[el_idx])\n",
    "                x = float(toks[bx_idx])\n",
    "                y = float(toks[by_idx])\n",
    "                z = float(toks[bz_idx])\n",
    "                # flatten 17 centroid pairs into 34-length list\n",
    "                raw_centroid_xy = []\n",
    "                for k in range(17):\n",
    "                    raw_centroid_xy.append(float(toks[cx_idx[k]]))\n",
    "                    raw_centroid_xy.append(float(toks[cy_idx[k]]))\n",
    "                smr = SMR(az, el, x, y, z)\n",
    "                # Optional rvec/tvec parsing\n",
    "                rvec = None\n",
    "                tvec = None\n",
    "                if rvec_idx_triplet is not None:\n",
    "                    try:\n",
    "                        rvec = [float(toks[rvec_idx_triplet[0]]), float(toks[rvec_idx_triplet[1]]), float(toks[rvec_idx_triplet[2]])]\n",
    "                    except Exception:\n",
    "                        rvec = None\n",
    "                if tvec_idx_triplet is not None:\n",
    "                    try:\n",
    "                        tvec = [float(toks[tvec_idx_triplet[0]]), float(toks[tvec_idx_triplet[1]]), float(toks[tvec_idx_triplet[2]])]\n",
    "                    except Exception:\n",
    "                        tvec = None\n",
    "                data_list.append(Data(smr, raw_centroid_xy, rvec=rvec, tvec=tvec))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if not data_list:\n",
    "        raise ValueError(f\"No valid rows parsed from {file_path}\")\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29519a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iPb_uv2pyr(keypoints, prm:Prm):\n",
    "    ypr = [0.0, 0.0, 0.0]\n",
    "    \n",
    "    # compute (u1,v1) and (u2,v2), coordinates of P1 and P2 in P3 frame\n",
    "    u1 = keypoints[0][0] - keypoints[1][0]\n",
    "    v1 = -(keypoints[0][1] - keypoints[1][1])\n",
    "    u2 = keypoints[2][0] - keypoints[1][0]\n",
    "    v2 = -(keypoints[2][1] - keypoints[1][1])\n",
    "\n",
    "    # compute roll for general cases (in degree)\n",
    "    roll = (math.atan2((u1 - u2), (v1 - v2))) * 180 / np.pi\n",
    "    sr = math.sin(roll * np.pi / 180)\n",
    "    cr = math.cos(roll * np.pi / 180)\n",
    "\n",
    "    m = math.sqrt(((u1 - u2) ** 2 + (v1 - v2) ** 2) / (prm.H1 - prm.H2) ** 2)\n",
    "    n = (sr * v1 - cr * u1) / prm.D\n",
    "    k = (sr * u1 + cr * v1 - prm.H1 * m) / prm.D\n",
    "\n",
    "    if abs(n) < 0.00001:\n",
    "        temp1 = m ** 2 + n ** 2 + k ** 2\n",
    "        temp2 = m ** 2 * n ** 2\n",
    "        ss = (temp1 - math.sqrt(temp1 ** 2 - 4 * temp2)) / (2 * temp2)\n",
    "        scale = math.sqrt(ss)\n",
    "    # when Probe is vertical\n",
    "    else:\n",
    "        scale = 1 / math.sqrt(m ** 2 + k ** 2)\n",
    "\n",
    "    # compute pitch and yaw (in degree)\n",
    "    yaw = (math.asin(n * scale)) * 180 / np.pi\n",
    "    pitch = (math.asin(k * scale / math.cos((yaw / 180) * np.pi))) * 180 / np.pi\n",
    "\n",
    "    ypr[0] = yaw\n",
    "    ypr[1] = pitch\n",
    "    ypr[2] = roll\n",
    "    \n",
    "    return ypr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4940eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deg2rad(deg: float) -> float:\n",
    "    return float(deg) * np.pi / 180.0\n",
    "\n",
    "\n",
    "def _rotz_deg(angle_deg: float) -> np.ndarray:\n",
    "    a = _deg2rad(angle_deg)\n",
    "    cz = float(np.cos(a)); sz = float(np.sin(a))\n",
    "    return np.array([[cz, -sz, 0.0],\n",
    "                     [sz,  cz, 0.0],\n",
    "                     [0.0, 0.0, 1.0]], dtype=np.float64)\n",
    "\n",
    "\n",
    "def _rotx_deg(angle_deg: float) -> np.ndarray:\n",
    "    a = _deg2rad(angle_deg)\n",
    "    cx = float(np.cos(a)); sx = float(np.sin(a))\n",
    "    return np.array([[1.0, 0.0, 0.0],\n",
    "                     [0.0,  cx, -sx],\n",
    "                     [0.0,  sx,  cx]], dtype=np.float64)\n",
    "\n",
    "\n",
    "def _roty_deg(angle_deg: float) -> np.ndarray:\n",
    "    a = _deg2rad(angle_deg)\n",
    "    cy = float(np.cos(a)); sy = float(np.sin(a))\n",
    "    return np.array([[ cy, 0.0, sy],\n",
    "                     [0.0, 1.0, 0.0],\n",
    "                     [-sy, 0.0, cy]], dtype=np.float64)\n",
    "\n",
    "\n",
    "def _euler_zxy_deg_to_rmat(yaw_deg: float, pitch_deg: float, roll_deg: float) -> np.ndarray:\n",
    "    \"\"\"Build rotation matrix from zxy Euler (degrees): yaw(z), pitch(x), roll(y).\"\"\"\n",
    "    return R.from_euler('zxy', [yaw_deg, pitch_deg, roll_deg], degrees=True).as_matrix()\n",
    "\n",
    "def _rmat_to_euler_zxy_deg(Rm: np.ndarray) -> tuple[float, float, float]:\n",
    "    \"\"\"Extract zxy Euler angles (degrees) from rotation matrix using SciPy; returns (yaw, pitch, roll).\"\"\"\n",
    "    Rm = np.asarray(Rm, dtype=np.float64)\n",
    "    yaw, pitch, roll = R.from_matrix(Rm).as_euler('zxy', degrees=True)\n",
    "    return float(yaw), float(pitch), float(roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda5814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_pose(subdir_num, fcinfb, prm, retro_normal_in_fp, solid_cube_param):\n",
    "    # Locate target path back_to_led/1\n",
    "    try:\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        # __file__ is not defined (e.g., running in Jupyter). Fall back to CWD.\n",
    "        script_dir = os.getcwd()\n",
    "    target_dir = os.path.join(script_dir, \"back_to_led\", str(subdir_num))\n",
    "\n",
    "    # Read three SMR coordinates from Single_Point_Data_*.txt (unchanged logic)\n",
    "    smr_txt = None\n",
    "    for name in os.listdir(target_dir):\n",
    "        if name.startswith(\"Single_Point_Data_\") and name.endswith(\".txt\"):\n",
    "            smr_txt = os.path.join(target_dir, name)\n",
    "            break\n",
    "    if smr_txt is None:\n",
    "        raise FileNotFoundError(\"Single_Point_Data_*.txt not found in back_to_led/1\")\n",
    "\n",
    "    smrs = read_ref_smr_from_txt(smr_txt)\n",
    "    if len(smrs) < 3:\n",
    "        raise ValueError(\"Need three SMR coordinates in Single_Point_Data_*.txt\")\n",
    "\n",
    "    # Extract three SMR positions and compute fsinft\n",
    "    p1 = np.array([smrs[0].x, smrs[0].y, smrs[0].z], dtype=np.float64)\n",
    "    p2 = np.array([smrs[1].x, smrs[1].y, smrs[1].z], dtype=np.float64)\n",
    "    p3 = np.array([smrs[2].x, smrs[2].y, smrs[2].z], dtype=np.float64)\n",
    "\n",
    "    # print(f\"SMR1: ({p1[0]}, {p1[1]}, {p1[2]})\")\n",
    "    # print(f\"SMR2: ({p2[0]}, {p2[1]}, {p2[2]})\")\n",
    "    # print(f\"SMR3: ({p3[0]}, {p3[1]}, {p3[2]})\")\n",
    "\n",
    "    fsinft = build_fsinft_from_three_points(p1, p2, p3)\n",
    "    \n",
    "    ypr_fsinft = _rmat_to_euler_zxy_deg(fsinft)\n",
    "    # print(f\"fsinft YPR (deg): yaw={ypr_fsinft[0]:.6f}, pitch={ypr_fsinft[1]:.6f}, roll={ypr_fsinft[2]:.6f}\")\n",
    "\n",
    "    # Read MatchedDataDump.dat via helper and print first four centroid pairs per row\n",
    "    mdd_path = os.path.join(target_dir, \"MatchedDataDump.dat\")\n",
    "    if not os.path.exists(mdd_path):\n",
    "        raise FileNotFoundError(\"MatchedDataDump.dat not found in back_to_led/1\")\n",
    "\n",
    "    data_list = read_iprobe_data_from_dat(mdd_path)\n",
    "    # Per-row: print first four centroid pairs and compute YPR using 3rd, 4th, 2nd centroids\n",
    "    iprobe_prm = Prm(prm[0], prm[1], prm[2])\n",
    "    smr_in_fs_comp_list = []\n",
    "    for d in data_list:\n",
    "        c = d.centroids\n",
    "        if len(c) >= 4:\n",
    "            # print(f\"Centroids: ({c[0][0]}, {c[0][1]}), ({c[1][0]}, {c[1][1]}), ({c[2][0]}, {c[2][1]}), ({c[3][0]}, {c[3][1]})\")\n",
    "            pts4 = [c[0], c[1], c[2], c[3]]\n",
    "            drop_idx = min(range(4), key=lambda i: pts4[i][1])\n",
    "            remaining = [pts4[i] for i in range(4) if i != drop_idx]\n",
    "            keypoints = sorted(remaining, key=lambda p: p[0], reverse=True)\n",
    "            # print(f\"Keypoints: {keypoints}\")\n",
    "            ypr = iPb_uv2pyr(keypoints, iprobe_prm)\n",
    "            # print(f\"fpinfc YPR bef (deg): yaw={ypr[0]:.6f}, pitch={ypr[1]:.6f}, roll={ypr[2]:.6f}\")\n",
    "            fpinfc = _euler_zxy_deg_to_rmat(ypr[0], ypr[1], ypr[2])\n",
    "\n",
    "            az_deg = d.smr.az\n",
    "            el_deg = d.smr.el\n",
    "            Rz = _rotz_deg(float(az_deg))\n",
    "            Rx = _rotx_deg(float(el_deg))\n",
    "            fbinft = Rz @ Rx\n",
    "            \n",
    "            fpinfb = fcinfb @ fpinfc\n",
    "            fpinft = fbinft @ fpinfb\n",
    "            fpinft_pyr = _rmat_to_euler_zxy_deg(fpinft)\n",
    "            # print(f\"fpinft YPR (deg): yaw={fpinft_pyr[0]:.6f}, pitch={fpinft_pyr[1]:.6f}, roll={fpinft_pyr[2]:.6f}\")\n",
    "            \n",
    "            fpinfs = np.linalg.solve(fsinft, fpinft)\n",
    "            fpinfs_pyr = _rmat_to_euler_zxy_deg(fpinfs)\n",
    "            # print(f\"fpinfs YPR (deg): yaw={fpinfs_pyr[0]:.6f}, pitch={fpinfs_pyr[1]:.6f}, roll={fpinfs_pyr[2]:.6f}\")\n",
    "            \n",
    "        smr_before_comp = [d.smr.x, d.smr.y, d.smr.z]\n",
    "        \n",
    "        scp = np.asarray(solid_cube_param, dtype=np.float64).reshape(-1,)\n",
    "        a_lat = scp[0:4]\n",
    "        a_long = scp[4:8]\n",
    "        \n",
    "        v_beam_fb = np.array([0.0, 1.0, 0.0], dtype=np.float64)\n",
    "        smr_norm_fb = fpinfb @ retro_normal_in_fp\n",
    "        nrm = float(np.linalg.norm(smr_norm_fb))\n",
    "        if nrm > 0.0:\n",
    "            smr_norm_fb = smr_norm_fb / nrm\n",
    "        else:\n",
    "            raise ValueError(\"smr_norm_fb norm is zero or negative, cannot normalize.\")\n",
    "\n",
    "        temp = float(np.clip(float(np.dot(v_beam_fb, smr_norm_fb)), -1.0, 1.0))\n",
    "        combo_angle_deg = float(np.degrees(np.arccos(temp)))\n",
    "\n",
    "        err_lat = float(a_lat[0] + a_lat[1] * combo_angle_deg + a_lat[2] * (combo_angle_deg ** 2) + a_lat[3] * (combo_angle_deg ** 3))\n",
    "        err_long = float(a_long[0] + a_long[1] * combo_angle_deg + a_long[2] * (combo_angle_deg ** 2) + a_long[3] * (combo_angle_deg ** 3))\n",
    "\n",
    "        v_temp = np.cross(smr_norm_fb, v_beam_fb)\n",
    "        v_lat_in_fb = np.cross(v_beam_fb, v_temp)\n",
    "        n = float(np.linalg.norm(v_lat_in_fb))\n",
    "        if n > 0.0:\n",
    "            v_lat_in_fb = v_lat_in_fb / n\n",
    "        else:\n",
    "            raise ValueError(\"v_lat_in_fb norm is zero or negative, cannot normalize.\")\n",
    "            \n",
    "        comp_fb = err_lat * v_lat_in_fb + err_long * np.array([0.0, -1.0, 0.0], dtype=np.float64)\n",
    "        comp_ft = fbinft @ comp_fb\n",
    "        smr_xyz_ft_comp = smr_before_comp + comp_ft\n",
    "        \n",
    "        smr_in_fs_comp = np.linalg.solve(fsinft, smr_xyz_ft_comp - p2)\n",
    "        # print(f\"smr_in_fs_comp: {smr_in_fs_comp[0]:.6f}, {smr_in_fs_comp[1]:.6f}, {smr_in_fs_comp[2]:.6f}\")\n",
    "        smr_in_fs_comp_list.append(smr_in_fs_comp)\n",
    "        \n",
    "    return np.mean(smr_in_fs_comp_list, axis=0)\n",
    "\n",
    "def get_pyr_list(fcinfb, prm, retro_normal_in_fp, solid_cube_param):\n",
    "    smr_in_fs_comp_list = []\n",
    "    for i in range(1, 8):\n",
    "        smr_in_fs_comp = process_single_pose(str(i), fcinfb, prm, retro_normal_in_fp, solid_cube_param)\n",
    "        if smr_in_fs_comp is not None:\n",
    "            smr_in_fs_comp_list.append(smr_in_fs_comp)\n",
    "            \n",
    "    if smr_in_fs_comp_list:\n",
    "        arr = np.asarray(smr_in_fs_comp_list, dtype=np.float64)\n",
    "        stds = np.std(arr, axis=0)\n",
    "        ptps = np.ptp(arr, axis=0)\n",
    "        print(f\"SMR_in_FS std: x={stds[0]:.6f}, y={stds[1]:.6f}, z={stds[2]:.6f}\")\n",
    "        print(f\"SMR_in_FS ptp: x={ptps[0]:.6f}, y={ptps[1]:.6f}, z={ptps[2]:.6f}\")\n",
    "        return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32140797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_smr_across_folders(fcinfb: np.ndarray, prm: list[float],\n",
    "                                 retro_normal_in_fp: np.ndarray, solid_cube_param: list[float]) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute per-folder mean smr_in_fs_comp and overall std/ptp across folders 1..7.\n",
    "    Returns (means_arr[N,3], stds[3], ptps[3]).\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    for i in range(1, 8):\n",
    "        mean_xyz = process_single_pose(str(i), fcinfb, prm, retro_normal_in_fp, solid_cube_param)\n",
    "        if mean_xyz is not None:\n",
    "            means.append(mean_xyz)\n",
    "    if not means:\n",
    "        return np.zeros((0, 3), dtype=np.float64), np.array([np.inf, np.inf, np.inf], dtype=np.float64), np.array([np.inf, np.inf, np.inf], dtype=np.float64)\n",
    "    means_arr = np.asarray(means, dtype=np.float64)\n",
    "    stds = np.std(means_arr, axis=0)\n",
    "    ptps = np.ptp(means_arr, axis=0)\n",
    "    return means_arr, stds, ptps\n",
    "\n",
    "\n",
    "def optimize_retro_normal_with_minimize(fcinfb: np.ndarray, prm: list[float], solid_cube_param: list[float],\n",
    "                                        retro_init: np.ndarray | None = None,\n",
    "                                        max_tilt_deg: float = 10.0):\n",
    "    \"\"\"\n",
    "    Optimize retro_normal_in_fp using scipy.optimize.minimize.\n",
    "    Parameterization: spherical angles (theta, phi) to keep unit norm.\n",
    "    Objective: minimize sum of squared std of smr_in_fs_comp across folders.\n",
    "    \"\"\"\n",
    "    from scipy.optimize import minimize\n",
    "\n",
    "    def angles_to_unit(theta: float, phi: float) -> np.ndarray:\n",
    "        ct = float(np.cos(theta))\n",
    "        st = float(np.sin(theta))\n",
    "        cp = float(np.cos(phi))\n",
    "        sp = float(np.sin(phi))\n",
    "        return np.array([st * cp, ct, st * sp], dtype=np.float64)\n",
    "\n",
    "    if retro_init is None:\n",
    "        retro_init = np.array([0.0, 1.0, 0.0], dtype=np.float64)\n",
    "    retro_init = retro_init / (np.linalg.norm(retro_init) + 1e-12)\n",
    "    theta0 = float(np.arccos(np.clip(retro_init[1], -1.0, 1.0)))\n",
    "    phi0 = float(np.arctan2(retro_init[2], retro_init[0]))\n",
    "\n",
    "    def objective(x: np.ndarray) -> float:\n",
    "        retro = angles_to_unit(x[0], x[1])\n",
    "        _, stds, _ = _evaluate_smr_across_folders(fcinfb, prm, retro, solid_cube_param)\n",
    "        return float(np.sum(stds * stds))\n",
    "\n",
    "    max_tilt = float(np.deg2rad(max_tilt_deg))\n",
    "    res = minimize(\n",
    "        objective,\n",
    "        x0=np.array([theta0, phi0], dtype=np.float64),\n",
    "        method=\"L-BFGS-B\",\n",
    "        bounds=[(0.0, max_tilt), (-np.pi, np.pi)],\n",
    "        options={\"maxiter\": 100, \"ftol\": 1e-12, \"gtol\": 1e-12, \"disp\": True},\n",
    "    )\n",
    "    retro_opt = angles_to_unit(res.x[0], res.x[1])\n",
    "    return retro_opt, res\n",
    "\n",
    "\n",
    "def optimize_solid_cube_with_least_squares(fcinfb: np.ndarray, prm: list[float], retro_normal_in_fp: np.ndarray,\n",
    "                                           solid_cube_init: list[float]):\n",
    "    \"\"\"\n",
    "    Optimize solid_cube_param using scipy.optimize.least_squares.\n",
    "    Residuals: per-folder mean smr_in_fs_comp minus overall mean to reduce cross-folder variance.\n",
    "    \"\"\"\n",
    "    from scipy.optimize import least_squares\n",
    "\n",
    "    def residuals(x: np.ndarray) -> np.ndarray:\n",
    "        means_arr, _, _ = _evaluate_smr_across_folders(fcinfb, prm, retro_normal_in_fp, x.tolist())\n",
    "        if means_arr.shape[0] == 0:\n",
    "            return np.array([1e6, 1e6, 1e6], dtype=np.float64)\n",
    "        overall_mean = np.mean(means_arr, axis=0)\n",
    "        return (means_arr - overall_mean).reshape(-1)\n",
    "\n",
    "    x0 = np.asarray(solid_cube_init, dtype=np.float64)\n",
    "    solid_cube_bounds = [(-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1),\n",
    "                         (8.0, 11.0), (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1)]\n",
    "    lb = np.array([b[0] for b in solid_cube_bounds], dtype=np.float64)\n",
    "    ub = np.array([b[1] for b in solid_cube_bounds], dtype=np.float64)\n",
    "    res = least_squares(\n",
    "        residuals,\n",
    "        x0,\n",
    "        bounds=(lb, ub),\n",
    "        ftol=1e-9,\n",
    "        xtol=1e-9,\n",
    "        gtol=1e-9,\n",
    "        loss=\"soft_l1\",\n",
    "        f_scale=0.5,\n",
    "        max_nfev=500,\n",
    "        verbose=2,\n",
    "    )\n",
    "    return res.x.tolist(), res\n",
    "\n",
    "\n",
    "def optimize_retro_and_solidcube(fcinfb: np.ndarray, prm: list[float],\n",
    "                                 retro_init: np.ndarray | None = None, solid_cube_init: list[float] | None = None,\n",
    "                                 iters: int = 2):\n",
    "    \"\"\"\n",
    "    Alternating optimization:\n",
    "    1) Fix solid_cube, optimize retro_normal (minimize)\n",
    "    2) Fix retro_normal, optimize solid_cube (least_squares)\n",
    "    \"\"\"\n",
    "    retro_init = np.array([0.0, 1.0, 0.0], dtype=np.float64) if retro_init is None else np.asarray(retro_init, dtype=np.float64)\n",
    "    solid_cube_init = [0.0] * 8 if solid_cube_init is None else [float(v) for v in solid_cube_init]\n",
    "\n",
    "    for _ in range(max(1, int(iters))):\n",
    "        retro, _ = optimize_retro_normal_with_minimize(fcinfb, prm, solid_cube_init, retro_init)\n",
    "        solid_cube, _ = optimize_solid_cube_with_least_squares(fcinfb, prm, retro_init, solid_cube_init)\n",
    "\n",
    "    # Initial report\n",
    "    _, stds0, ptps0 = _evaluate_smr_across_folders(fcinfb, prm, retro_init, solid_cube_init)\n",
    "    print(\"Initial SMR_in_FS std:\", stds0)\n",
    "    print(\"Initial SMR_in_FS ptp:\", ptps0)\n",
    "\n",
    "    _, stds, ptps = _evaluate_smr_across_folders(fcinfb, prm, retro, solid_cube)\n",
    "    print(\"Optimized retro_normal_in_fp:\", retro)\n",
    "    print(\"Optimized solid_cube_param:\", solid_cube)\n",
    "    print(\"SMR_in_FS std:\", stds)\n",
    "    print(\"SMR_in_FS ptp:\", ptps)\n",
    "    return retro, solid_cube, stds, ptps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2bf3578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         1.2543e-02                                    1.16e+02    \n",
      "       1              2         5.9025e-03      6.64e-03       4.80e-02       1.74e+00    \n",
      "       2              3         4.9540e-03      9.49e-04       3.26e-02       1.30e-01    \n",
      "       3              4         4.4919e-03      4.62e-04       7.70e-01       7.34e-04    \n",
      "       4              5         4.2922e-03      2.00e-04       4.34e-01       7.14e-05    \n",
      "       5              6         4.2348e-03      5.74e-05       6.40e-03       1.29e-01    \n",
      "       6              7         4.2300e-03      4.81e-06       5.60e-04       4.48e-02    \n",
      "       7              8         4.2300e-03      2.57e-08       2.65e-05       5.70e-03    \n",
      "       8              9         4.2300e-03      8.77e-10       1.50e-05       1.17e-04    \n",
      "       9             10         4.2300e-03      5.38e-11       2.28e-06       1.72e-07    \n",
      "      10             11         4.2300e-03      2.90e-13       2.31e-06       1.06e-07    \n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 11, initial cost 1.2543e-02, final cost 4.2300e-03, first-order optimality 1.06e-07.\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         1.2543e-02                                    1.16e+02    \n",
      "       1              2         5.9025e-03      6.64e-03       4.80e-02       1.74e+00    \n",
      "       2              3         4.9540e-03      9.49e-04       3.26e-02       1.30e-01    \n",
      "       3              4         4.4919e-03      4.62e-04       7.70e-01       7.34e-04    \n",
      "       4              5         4.2922e-03      2.00e-04       4.34e-01       7.14e-05    \n",
      "       5              6         4.2348e-03      5.74e-05       6.40e-03       1.29e-01    \n",
      "       6              7         4.2300e-03      4.81e-06       5.60e-04       4.48e-02    \n",
      "       7              8         4.2300e-03      2.57e-08       2.65e-05       5.70e-03    \n",
      "       8              9         4.2300e-03      8.77e-10       1.50e-05       1.17e-04    \n",
      "       9             10         4.2300e-03      5.38e-11       2.28e-06       1.72e-07    \n",
      "      10             11         4.2300e-03      2.90e-13       2.31e-06       1.06e-07    \n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 11, initial cost 1.2543e-02, final cost 4.2300e-03, first-order optimality 1.06e-07.\n",
      "Initial SMR_in_FS std: [0.01718167 0.01260305 0.05619975]\n",
      "Initial SMR_in_FS ptp: [0.04731828 0.03896254 0.19138484]\n",
      "Optimized retro_normal_in_fp: [0.00232457 0.99992165 0.01230009]\n",
      "Optimized solid_cube_param: [0.011890404602232228, -0.09999999999999999, 0.0033315683648671274, 3.642241761692338e-05, 10.999999999999998, -0.02481573674159523, -0.0001646984313714648, 6.006236769820733e-05]\n",
      "SMR_in_FS std: [0.01533125 0.01582841 0.0592075 ]\n",
      "SMR_in_FS ptp: [0.04629646 0.04883226 0.15713915]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00232457, 0.99992165, 0.01230009]),\n",
       " [0.011890404602232228,\n",
       "  -0.09999999999999999,\n",
       "  0.0033315683648671274,\n",
       "  3.642241761692338e-05,\n",
       "  10.999999999999998,\n",
       "  -0.02481573674159523,\n",
       "  -0.0001646984313714648,\n",
       "  6.006236769820733e-05],\n",
       " array([0.01533125, 0.01582841, 0.0592075 ]),\n",
       " array([0.04629646, 0.04883226, 0.15713915]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcinfb = np.array([[ 9.99601553e-01, -1.57124273e-04, -2.82260604e-02],\n",
    "                   [ 3.05766202e-04,  9.99986109e-01,  5.26188484e-03],\n",
    "                   [ 2.82248415e-02, -5.26841884e-03,  9.99587716e-01]], dtype=np.float64)\n",
    "prm = [66.9458282000292, 79.5609903283944, -79.14074678394307]\n",
    "retro_normal_in_fp = np.array([0, 1, 0], dtype=np.float64)\n",
    "solid_cube_param = [0.03337562528583654, -0.03232965420056112, 0.0034968402730924026, -9.89459226909839e-05,\n",
    "                    9.85132442276245, 0.003432913527927372, -0.0006334825927563309, 2.1592940299138004e-05]\n",
    "optimize_retro_and_solidcube(fcinfb, prm, retro_normal_in_fp, solid_cube_param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
